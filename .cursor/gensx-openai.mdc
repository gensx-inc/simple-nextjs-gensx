---
description: How to use the openai gensx package
globs: 
alwaysApply: true
---

## OpenAI Package Syntax

The `@gensx/openai`â€‰package provides OpenAI API compatible components for GenSX.

### OpenAIProvider

The `OpenAIProvider` component initializes and provides an OpenAI client instance to all child components. 

By configuring the baseURL, you can also use the OpenAIProvider with other OpenAI compatible APIs like Groq and x.AI:

```tsx
<OpenAIProvider
  apiKey="your-api-key" // Your Groq API key
  baseURL="https://api.groq.com/openai/v1"
/>
```

### GSXChatCompletion

The `GSXChatCompletion` component is an advanced chat completion component that provides enhanced features beyond the standard OpenAI API. It supports structured output, tool calling, and streaming, with automatic handling of tool execution.

#### Structured outputs

```tsx
import * as gensx from "@gensx/core";
import { GSXChatCompletion, OpenAIProvider } from "@gensx/openai";
import { z } from "zod";

const ExtractEntitiesSchema = z.object({
  people: z.array(z.string()),
  places: z.array(z.string()),
  organizations: z.array(z.string()),
});

const StructuredOutputExample = gensx.Component<{}, typeof ExtractEntitiesSchema>(
  "StructuredOutputExample",
  () => (
    <OpenAIProvider apiKey={process.env.OPENAI_API_KEY}>
      <GSXChatCompletion
        model="gpt-4o-mini"
        messages={[
          { role: "system", content: "Extract people, places, and organizations from text." },
          { role: "user", content: "John Doe is a software engineer at Google." },
        ]}
        outputSchema={ExtractEntitiesSchema}
      />
    </OpenAIProvider>
  ),
);
```

#### Tools

```tsx
import * as gensx from "@gensx/core";
import { GSXChatCompletion, GSXTool, OpenAIProvider } from "@gensx/openai";
  
// Define the schema as a Zod object
const weatherSchema = z.object({
  location: z.string(),
});

// Use z.infer to get the type for our parameters
type WeatherParams = z.infer<typeof weatherSchema>;

// Create the tool
const tool = new GSXTool({
  name: "get_weather",
  description: "get the weather for a given location",
  schema: weatherSchema,
  run: async ({ location }: WeatherParams) => {
    console.log("getting weather for", location);
    const weather = ["sunny", "cloudy", "rainy", "snowy"];
    return Promise.resolve({
      weather: weather[Math.floor(Math.random() * weather.length)],
    });
  },
});

  const ToolsExample = gensx.Component<{}, ChatCompletionOutput>(
  "ToolsExample",
  () => (
    <OpenAIProvider apiKey={process.env.OPENAI_API_KEY}>
      <GSXChatCompletion
        messages={[
          {
            role: "system",
            content: "You're a helpful weather assistant.",
          },
          {
            role: "user",
            content: `What's the weather like in Seattle?'`,
          },
        ]}
        model="gpt-4o-mini"
        temperature={0.7}
        tools={[tool]}
      />
    </OpenAIProvider>
  ),
);
```

### ChatCompletion (Simplified)

The `ChatCompletion` component provides a simplified interface for chat completions. It returns either a string or a simple stream of string tokens while having identical inputs to the OpenAI API. 

```tsx
const SimpleChat = gensx.Component<{}, string>(
  "SimpleChat",
  () => (
    <OpenAIProvider apiKey={process.env.OPENAI_API_KEY}>
      <ChatCompletion
        model="gpt-4o-mini"
        messages={[
          { role: "system", content: "You're a helpful assistant." },
          { role: "user", content: "Define AI." },
        ]}
        temperature={0.7}
      />
    </OpenAIProvider>
  ),
);
```

### OpenAIChatCompletion (Low-Level)

The `OpenAIChatCompletion` component is a low-level component that directly maps to the OpenAI SDK. It has identical inputs and outputs to the OpenAI API, making it suitable for advanced use cases where you need full control.

```tsx
import { ChatCompletion as ChatCompletionOutput} from "openai/resources/chat/completions.js";

const LowLevelChat = gensx.Component<{}, ChatCompletionOutput>(
  "LowLevelChat",
  () => (
    <OpenAIProvider apiKey={process.env.OPENAI_API_KEY}>
      <OpenAIChatCompletion
        model="gpt-4o-mini"
        messages={[
          { role: "system", content: "You're a helpful assistant." },
          { role: "user", content: "Explain quantum computing." },
        ]}
      />
    </OpenAIProvider>
  ),
);
```

---